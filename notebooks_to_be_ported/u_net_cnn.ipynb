{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMGSAn7R6he_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from keras.callbacks import Callback\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "snQ-skMW7Zqz",
        "outputId": "a4cfb8b5-73bd-45b4-ea0f-61ea35c0e76b"
      },
      "outputs": [],
      "source": [
        "# this is when the input shapes are 512 x 512 x 9. this is too big, it causes a runtime error because not enough RAM is available\n",
        "'''\n",
        "input_shape = (512, 512, 9)\n",
        "\n",
        "def build_unet():\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    # Decoder\n",
        "    up4 = UpSampling2D(size=(2, 2))(pool3)\n",
        "    merge4 = concatenate([conv3, up4], axis=3)\n",
        "    conv4 = Conv2D(256, 3, activation='relu', padding='same')(merge4)\n",
        "\n",
        "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
        "    merge5 = concatenate([conv2, up5], axis=3)\n",
        "    conv5 = Conv2D(128, 3, activation='relu', padding='same')(merge5)\n",
        "\n",
        "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
        "    merge6 = concatenate([conv1, up6], axis=3)\n",
        "    conv6 = Conv2D(64, 3, activation='relu', padding='same')(merge6)\n",
        "\n",
        "    # Output layer\n",
        "    output = Conv2D(3, 1, activation='sigmoid')(conv6)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "model = build_unet()\n",
        "model.summary()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NKgmcU90y6C4",
        "outputId": "85158045-25e0-4f16-9773-094cec913105"
      },
      "outputs": [],
      "source": [
        "# this is when the input shapes are 32 x 32 x 9. since the images are smaller here, there is no runtime error\n",
        "'''\n",
        "input_shape = (32, 32, 9)\n",
        "\n",
        "def build_unet():\n",
        "    inputs = Input(shape=input_shape) #define the shape of the input which is 32x32x9 with each 3 channels representing one of the images\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs) #64 kernels/fi\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    # Decoder\n",
        "    up4 = UpSampling2D(size=(2, 2))(pool3)\n",
        "    merge4 = concatenate([conv3, up4], axis=3)\n",
        "    conv4 = Conv2D(256, 3, activation='relu', padding='same')(merge4)\n",
        "\n",
        "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
        "    merge5 = concatenate([conv2, up5], axis=3)\n",
        "    conv5 = Conv2D(128, 3, activation='relu', padding='same')(merge5)\n",
        "\n",
        "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
        "    merge6 = concatenate([conv1, up6], axis=3)\n",
        "    conv6 = Conv2D(64, 3, activation='relu', padding='same')(merge6)\n",
        "\n",
        "    # Output layer\n",
        "    output = Conv2D(3, 1, activation='sigmoid')(conv6)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "model = build_unet()\n",
        "model.summary()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Oij9ASxnyljd",
        "outputId": "c87aa2d0-1354-4221-86f1-e68358e6699d"
      },
      "outputs": [],
      "source": [
        "# this is when the input shapes are 32 x 32 x 12. since the images are smaller here, there is no runtime error\n",
        "'''\n",
        "input_shape = (32, 32, 12)\n",
        "\n",
        "def build_unet():\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    # Decoder\n",
        "    up4 = UpSampling2D(size=(2, 2))(pool3)\n",
        "    merge4 = concatenate([conv3, up4], axis=3)\n",
        "    conv4 = Conv2D(256, 3, activation='relu', padding='same')(merge4)\n",
        "\n",
        "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
        "    merge5 = concatenate([conv2, up5], axis=3)\n",
        "    conv5 = Conv2D(128, 3, activation='relu', padding='same')(merge5)\n",
        "\n",
        "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
        "    merge6 = concatenate([conv1, up6], axis=3)\n",
        "    conv6 = Conv2D(64, 3, activation='relu', padding='same')(merge6)\n",
        "\n",
        "    # Output layer\n",
        "    output = Conv2D(3, 1, activation='sigmoid')(conv6)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "model = build_unet()\n",
        "model.summary()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m41iHTupCOpm",
        "outputId": "a4a86fa8-9c4a-40c4-f51f-7f1ad53a3359"
      },
      "outputs": [],
      "source": [
        "# this is when the input shapes are 32 x 32 x 15. since the images are smaller here, there is no runtime error\n",
        "\n",
        "input_shape = (32, 32, 15)\n",
        "\n",
        "def build_unet():\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
        "\n",
        "    # Decoder\n",
        "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
        "    merge6 = concatenate([conv4, up6], axis=-1)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
        "\n",
        "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
        "    merge7 = concatenate([conv3, up7], axis=-1)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
        "\n",
        "    up8 = UpSampling2D(size=(2, 2))(conv7)\n",
        "    merge8 = concatenate([conv2, up8], axis=-1)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
        "\n",
        "    up9 = UpSampling2D(size=(2, 2))(conv8)\n",
        "    merge9 = concatenate([conv1, up9], axis=-1)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
        "\n",
        "    # Output layer\n",
        "    output = Conv2D(3, 1, activation='sigmoid', padding='same')(conv9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "model = build_unet()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osUlIVd6sOah",
        "outputId": "ca572128-34a7-419c-dd2e-816a8c400178"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "load_path = '/content/drive/My Drive/Urbanization Project/arrays of graphs/crops_array.npy'\n",
        "loaded_crops_array = np.load(load_path, allow_pickle = True)\n",
        "print(agr_array.shape)\n",
        "\n",
        "\n",
        "load_path = '/content/drive/My Drive/Urbanization Project/arrays of graphs/years_array.npy'\n",
        "loaded_years_array = np.load(load_path, allow_pickle = True)\n",
        "print(precip_temp_urb_array.shape)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2GrCcG-2y9P",
        "outputId": "6f181752-e22f-42d0-839a-8cd9accb65b5"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "load_path = '/content/drive/My Drive/Urbanization Project/arrays of graphs/years_array_32.npy'\n",
        "loaded_years_array = np.load(load_path, allow_pickle = True)\n",
        "print(loaded_years_array.shape)\n",
        "\n",
        "import numpy as np\n",
        "load_path = '/content/drive/My Drive/Urbanization Project/arrays of graphs/crops_array_32.npy'\n",
        "loaded_crops_array = np.load(load_path, allow_pickle = True)\n",
        "print(loaded_crops_array.shape)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4PhUrtpy7Jy",
        "outputId": "563363f8-c0ad-40f8-a2de-ab54d0e78ff0"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "load_path = '/content/drive/My Drive/Urbanization Project/arrays of graphs/years_array_32_segmented.npy'\n",
        "loaded_years_array = np.load(load_path, allow_pickle = True)\n",
        "print(loaded_years_array.shape)\n",
        "\n",
        "\n",
        "load_path = '/content/drive/My Drive/Urbanization Project/arrays of graphs/crops_array_32_segmented.npy'\n",
        "loaded_crops_array = np.load(load_path, allow_pickle = True)\n",
        "print(loaded_crops_array.shape)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1QWsJLPCcLA",
        "outputId": "2d869f17-43bc-46e3-e596-e9354f42a60e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "load_path = '/content/drive/My Drive/Urbanization Project/arrays of graphs/years_array_32_segmented_prevUrb.npy'\n",
        "loaded_years_array = np.load(load_path, allow_pickle = True)\n",
        "print(loaded_years_array.shape)\n",
        "\n",
        "\n",
        "load_path = '/content/drive/My Drive/Urbanization Project/arrays of graphs/crops_array_32_segmented_prevUrb.npy'\n",
        "loaded_crops_array = np.load(load_path, allow_pickle = True)\n",
        "print(loaded_crops_array.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-k6uCOF-nc1E"
      },
      "outputs": [],
      "source": [
        "loss_function = MeanSquaredError()\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "\n",
        "model = build_unet()\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics = ['mae', 'accuracy'])\n",
        "\n",
        "X_train = loaded_years_array\n",
        "Y_train = loaded_crops_array\n",
        "\n",
        "# X_train, X_test, Y_train, Y_test = train_test_split(loaded_years_array, loaded_crops_array, test_size = 0.2, random_state = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4Pzt_cp2iVF",
        "outputId": "de4b46a2-da5e-4cc2-8734-877e4cf0549b"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, Y_train, batch_size=16, epochs=8, validation_split = 0.1)\n",
        "\n",
        "print(f\"Final Training MAE: {history.history['mae'][-1]:.4f}\")\n",
        "print(f\"Final Validation MAE: {history.history['val_mae'][-1]:.4f}\")\n",
        "\n",
        "print(f\"Final Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "fYJOt2p878uv",
        "outputId": "a72ef8f5-3c4c-421b-8f59-cb83fefbfbb9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
