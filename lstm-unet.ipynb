{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# LSTM-UNet Model Testing Notebook\n",
       "\n",
       "This notebook tests the LSTM-UNet hybrid model for urban crop yield prediction. This model combines LSTM for temporal processing with U-Net for spatial processing, making it suitable for spatio-temporal data."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 1. Setup and Imports"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import os\n",
       "import numpy as np\n",
       "import torch\n",
       "from torch.utils.data import DataLoader, random_split\n",
       "import matplotlib.pyplot as plt\n",
       "import sys\n",
       "\n",
       "# Add src to path for imports\n",
       "sys.path.append('.')\n",
       "\n",
       "# Import custom modules\n",
       "from src.models.lstm_unet import LSTMUNet\n",
       "from src.data.dataset import TemporalUrbanCropDataset\n",
       "from src.training import LSTMUNetTrainer\n",
       "from src.utils import set_seed, get_device, ensure_dir, visualize_prediction, calculate_metrics\n",
       "\n",
       "# Set random seed for reproducibility\n",
       "set_seed(42)\n",
       "\n",
       "# Check for CUDA\n",
       "device = get_device()\n",
       "print(f\"Using device: {device}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. Configuration"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Configuration settings\n",
       "config = {\n",
       "    'data_dir': 'data/processed',  # Directory with processed data\n",
       "    'model_dir': 'models',         # Directory to save trained models\n",
       "    'visualize_dir': 'visualizations',  # Directory for visualizations\n",
       "    'batch_size': 16,              # Batch size for training\n",
       "    'epochs': 10,                  # Number of epochs (reduced for testing)\n",
       "    'learning_rate': 0.001,        # Learning rate\n",
       "    'test_split': 0.2,             # Fraction of data for testing\n",
       "    'val_split': 0.1,              # Fraction of training data for validation\n",
       "    'time_steps': 23               # Number of time steps for LSTM processing\n",
       "}\n",
       "\n",
       "# Create necessary directories\n",
       "ensure_dir(config['model_dir'])\n",
       "ensure_dir(config['visualize_dir'])"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 3. Load Data\n",
       "\n",
       "For this notebook, we assume that the data has already been processed and saved as numpy arrays. If not, you'll need to run the data processing scripts first."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Load processed data\n",
       "def load_data(config):\n",
       "    \"\"\"Load preprocessed data\"\"\"\n",
       "    x_path = os.path.join(config['data_dir'], 'years_array_32_segmented_prevUrb.npy')\n",
       "    y_path = os.path.join(config['data_dir'], 'crops_array_32_segmented_prevUrb.npy')\n",
       "    \n",
       "    if os.path.exists(x_path) and os.path.exists(y_path):\n",
       "        print(\"Loading preprocessed data...\")\n",
       "        X_data = np.load(x_path)\n",
       "        y_data = np.load(y_path)\n",
       "        print(f\"X_data shape: {X_data.shape}\")\n",
       "        print(f\"y_data shape: {y_data.shape}\")\n",
       "        return X_data, y_data\n",
       "    else:\n",
       "        raise FileNotFoundError(f\"Preprocessed data not found at {x_path} and {y_path}. Please run data preprocessing first.\")\n",
       "\n",
       "try:\n",
       "    X_data, y_data = load_data(config)\n",
       "    \n",
       "    # Sample visualization of the data\n",
       "    plt.figure(figsize=(15, 5))\n",
       "    \n",
       "    # Input features (first sample, first 3 channels)\n",
       "    plt.subplot(1, 2, 1)\n",
       "    plt.imshow(np.transpose(X_data[0][:3], (1, 2, 0)))\n",
       "    plt.title('Input Features (First 3 Channels)')\n",
       "    plt.axis('off')\n",
       "    \n",
       "    # Target output\n",
       "    plt.subplot(1, 2, 2)\n",
       "    plt.imshow(np.transpose(y_data[0], (1, 2, 0)))\n",
       "    plt.title('Target Output')\n",
       "    plt.axis('off')\n",
       "    \n",
       "    plt.tight_layout()\n",
       "    plt.show()\n",
       "    \n",
       "except FileNotFoundError as e:\n",
       "    print(f\"Error: {e}\")\n",
       "    print(\"Using dummy data for demonstration purposes...\")\n",
       "    # Create dummy data for demonstration\n",
       "    # Note: For LSTM-UNet, we'll reshape this later\n",
       "    X_data = np.random.rand(100, 15, 32, 32)  # [samples, channels, height, width]\n",
       "    y_data = np.random.rand(100, 3, 32, 32)   # [samples, channels, height, width]\n",
       "    print(f\"Dummy X_data shape: {X_data.shape}\")\n",
       "    print(f\"Dummy y_data shape: {y_data.shape}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 4. Create Data Loaders with Temporal Reshaping\n",
       "\n",
       "For LSTM-UNet, we need to reshape the data to include temporal information. We'll use the TemporalUrbanCropDataset class which handles this reshaping."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def create_data_loaders(X_data, y_data, config):\n",
       "    \"\"\"Create train, validation, and test data loaders with temporal reshaping\"\"\"\n",
       "    # Create dataset with temporal reshaping\n",
       "    dataset = TemporalUrbanCropDataset(X_data, y_data, time_steps=config['time_steps'])\n",
       "    \n",
       "    # Determine the number of samples for each split\n",
       "    total_samples = len(dataset)\n",
       "    test_size = int(total_samples * config['test_split'])\n",
       "    train_size = total_samples - test_size\n",
       "    val_size = int(train_size * config['val_split'])\n",
       "    train_size = train_size - val_size\n",
       "    \n",
       "    print(f\"Total samples: {total_samples}\")\n",
       "    print(f\"Training samples: {train_size}\")\n",
       "    print(f\"Validation samples: {val_size}\")\n",
       "    print(f\"Test samples: {test_size}\")\n",
       "    \n",
       "    # Split into train, validation, and test sets\n",
       "    train_dataset, test_dataset = random_split(\n",
       "        dataset, [train_size + val_size, test_size],\n",
       "        generator=torch.Generator().manual_seed(42)\n",
       "    )\n",
       "    \n",
       "    train_dataset, val_dataset = random_split(\n",
       "        train_dataset, [train_size, val_size],\n",
       "        generator=torch.Generator().manual_seed(42)\n",
       "    )\n",
       "    \n",
       "    # Create data loaders\n",
       "    train_loader = DataLoader(\n",
       "        train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=2\n",
       "    )\n",
       "    \n",
       "    val_loader = DataLoader(\n",
       "        val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=2\n",
       "    )\n",
       "    \n",
       "    test_loader = DataLoader(\n",
       "        test_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=2\n",
       "    )\n",
       "    \n",
       "    return train_loader, val_loader, test_loader\n",
       "\n",
       "# Create data loaders\n",
       "train_loader, val_loader, test_loader = create_data_loaders(X_data, y_data, config)\n",
       "\n",
       "# Check the shape of the data after temporal reshaping\n",
       "for x_batch, y_batch in train_loader:\n",
       "    print(f\"Batch shapes after temporal reshaping:\")\n",
       "    print(f\"x_batch shape: {x_batch.shape}\")  # Should be [batch, time_steps, height, width, channels_per_step]\n",
       "    print(f\"y_batch shape: {y_batch.shape}\")  # Should be [batch, channels, height, width]\n",
       "    break"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 5. Initialize LSTM-UNet Model"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Initialize LSTM-UNet model\n",
       "def initialize_model(config):\n",
       "    \"\"\"Initialize LSTM-UNet model and trainer\"\"\"\n",
       "    # Create LSTM-UNet model\n",
       "    # input_shape=(time_steps, height, width, channels_per_step)\n",
       "    channels_per_step = 15 // config['time_steps']\n",
       "    model = LSTMUNet(input_shape=(config['time_steps'], 32, 32, channels_per_step), \n",
       "                    lstm_units=16, unet_filters=16)\n",
       "    \n",
       "    print(f\"Model created with {sum(p.numel() for p in model.parameters() if p.requires_grad)} trainable parameters\")\n",
       "    \n",
       "    # Create trainer\n",
       "    trainer = LSTMUNetTrainer(model, device=device)\n",
       "    trainer.compile(\n",
       "        optimizer='adam',\n",
       "        learning_rate=config['learning_rate'],\n",
       "        criterion='mse'\n",
       "    )\n",
       "    \n",
       "    return model, trainer\n",
       "\n",
       "# Initialize model and trainer\n",
       "model, trainer = initialize_model(config)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 6. Train the Model\n",
       "\n",
       "Train the LSTM-UNet model for a few epochs. For full training, you would increase the number of epochs."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def train_model(trainer, train_loader, val_loader, config):\n",
       "    \"\"\"Train the model and save checkpoints\"\"\"\n",
       "    # Create callback for model checkpoint\n",
       "    from src.training import model_checkpoint, early_stopping\n",
       "    \n",
       "    checkpoint_path = os.path.join(config['model_dir'], 'lstm-unet_best.pth')\n",
       "    callbacks = [\n",
       "        model_checkpoint(checkpoint_path, monitor='val_loss', save_best_only=True),\n",
       "        early_stopping(patience=5, monitor='val_loss')\n",
       "    ]\n",
       "    \n",
       "    # Train the model\n",
       "    print(f\"Starting training for {config['epochs']} epochs...\")\n",
       "    try:\n",
       "        history = trainer.fit(\n",
       "            train_loader,\n",
       "            val_loader=val_loader,\n",
       "            epochs=config['epochs'],\n",
       "            callbacks=callbacks\n",
       "        )\n",
       "    except KeyboardInterrupt:\n",
       "        print(\"Training interrupted by user\")\n",
       "    \n",
       "    # Save the final model\n",
       "    model_path = os.path.join(config['model_dir'], 'lstm-unet_final.pth')\n",
       "    trainer.save_model(model_path)\n",
       "    \n",
       "    return trainer\n",
       "\n",
       "# Train the model (uncomment to run training)\n",
       "# trainer = train_model(trainer, train_loader, val_loader, config)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 7. Plot Training History\n",
       "\n",
       "After training, plot the loss and metrics over epochs."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Plot training history (run after training)\n",
       "def plot_history(trainer, config):\n",
       "    \"\"\"Plot training history\"\"\"\n",
       "    history_path = os.path.join(config['visualize_dir'], 'lstm-unet_history.png')\n",
       "    trainer.plot_history(save_path=history_path)\n",
       "    \n",
       "# If you've trained the model, uncomment to plot the history\n",
       "# plot_history(trainer, config)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 8. Load Best Model and Evaluate\n",
       "\n",
       "Load the best model from checkpoint and evaluate on the test set."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def load_best_model(config):\n",
       "    \"\"\"Load the best model from checkpoint\"\"\"\n",
       "    # Initialize model\n",
       "    channels_per_step = 15 // config['time_steps']\n",
       "    model = LSTMUNet(input_shape=(config['time_steps'], 32, 32, channels_per_step), \n",
       "                    lstm_units=16, unet_filters=16)\n",
       "    \n",
       "    trainer = LSTMUNetTrainer(model, device=device)\n",
       "    trainer.compile(optimizer='adam', learning_rate=config['learning_rate'], criterion='mse')\n",
       "    \n",
       "    # Load checkpoint\n",
       "    checkpoint_path = os.path.join(config['model_dir'], 'lstm-unet_best.pth')\n",
       "    if os.path.exists(checkpoint_path):\n",
       "        print(f\"Loading model from {checkpoint_path}\")\n",
       "        trainer.load_model(checkpoint_path)\n",
       "    else:\n",
       "        print(f\"Checkpoint not found at {checkpoint_path}. Using untrained model.\")\n",
       "    \n",
       "    return model, trainer\n",
       "\n",
       "# Load the best model\n",
       "# Uncomment after training or if you have a saved model\n",
       "# best_model, best_trainer = load_best_model(config)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 9. Evaluate on Test Set"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def evaluate_model(trainer, test_loader, config):\n",
       "    \"\"\"Evaluate the model on the test set\"\"\"\n",
       "    print(\"Evaluating model on test set...\")\n",
       "    test_loss, test_metrics = trainer.evaluate(test_loader)\n",
       "    print(f\"Test Loss: {test_loss:.4f}, Test MAE: {test_metrics['mae']:.4f}\")\n",
       "    \n",
       "    # Visualize some predictions\n",
       "    vis_path = os.path.join(config['visualize_dir'], 'lstm-unet_predictions.png')\n",
       "    \n",
       "    # Custom visualization for LSTM-UNet (adapting for temporal data)\n",
       "    model = trainer.model\n",
       "    model.eval()\n",
       "    device = get_device()\n",
       "    model.to(device)\n",
       "    \n",
       "    # Get samples\n",
       "    samples = []\n",
       "    with torch.no_grad():\n",
       "        for batch_idx, (x, y) in enumerate(test_loader):\n",
       "            if batch_idx >= 5:  # Get 5 samples\n",
       "                break\n",
       "            \n",
       "            x = x.to(device)\n",
       "            pred = model(x)\n",
       "            samples.append((x.cpu().numpy(), y.cpu().numpy(), pred.cpu().numpy()))\n",
       "    \n",
       "    # Plot\n",
       "    fig, axes = plt.subplots(len(samples), 3, figsize=(15, 5*len(samples)))\n",
       "    \n",
       "    for i, (x, y, pred) in enumerate(samples):\n",
       "        # Input (show last time step)\n",
       "        axes[i, 0].imshow(x[0, -1])\n",
       "        axes[i, 0].set_title('Input (Last Time Step)')\n",
       "        axes[i, 0].axis('off')\n",
       "        \n",
       "        # Ground truth\n",
       "        axes[i, 1].imshow(np.transpose(y[0], (1, 2, 0)))\n",
       "        axes[i, 1].set_title('Ground Truth')\n",
       "        axes[i, 1].axis('off')\n",
       "        \n",
       "        # Prediction\n",
       "        axes[i, 2].imshow(np.transpose(pred[0], (1, 2, 0)))\n",
       "        axes[i, 2].set_title('Prediction')\n",
       "        axes[i, 2].axis('off')\n",
       "    \n",
       "    plt.tight_layout()\n",
       "    plt.savefig(vis_path)\n",
       "    plt.show()\n",
       "    \n",
       "    return test_loss, test_metrics\n",
       "\n",
       "# Evaluate on test set\n",
       "# Uncomment after loading a trained model\n",
       "# test_loss, test_metrics = evaluate_model(best_trainer, test_loader, config)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 10. Analyze Temporal Predictions\n",
       "\n",
       "Since LSTM-UNet handles temporal data, we can analyze how predictions change over time."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def analyze_temporal_predictions(model, X_data, y_data, config):\n",
       "    \"\"\"Analyze how predictions change with different temporal inputs\"\"\"\n",
       "    model.eval()\n",
       "    model.to(device)\n",
       "    \n",
       "    # Create a dataset with reduced time steps for analysis\n",
       "    time_steps_to_test = [5, 10, 15, 20, config['time_steps']]\n",
       "    \n",
       "    plt.figure(figsize=(15, 10))\n",
       "    \n",
       "    # Get a sample\n",
       "    sample_idx = 0\n",
       "    \n",
       "    # Target output\n",
       "    plt.subplot(2, 3, 1)\n",
       "    plt.imshow(np.transpose(y_data[sample_idx], (1, 2, 0)))\n",
       "    plt.title('Target Output')\n",
       "    plt.axis('off')\n",
       "    \n",
       "    # Make predictions with different time steps\n",
       "    for i, ts in enumerate(time_steps_to_test):\n",
       "        if i >= 5:  # Only show 5 predictions\n",
       "            break\n",
       "            \n",
       "        # Create a temporal dataset\n",
       "        temp_dataset = TemporalUrbanCropDataset(X_data[sample_idx:sample_idx+1], \n",
       "                                              y_data[sample_idx:sample_idx+1], \n",
       "                                              time_steps=ts)\n",
       "        x_temp, y_temp = temp_dataset[0]\n",
       "        \n",
       "        # Make prediction\n",
       "        with torch.no_grad():\n",
       "            x_temp = x_temp.unsqueeze(0).to(device)  # Add batch dimension\n",
       "            pred = model(x_temp)\n",
       "        \n",
       "        # Plot prediction\n",
       "        plt.subplot(2, 3, i+2)\n",
       "        plt.imshow(np.transpose(pred[0].cpu().numpy(), (1, 2, 0)))\n",
       "        plt.title(f'Prediction with {ts} Time Steps')\n",
       "        plt.axis('off')\n",
       "    \n",
       "    plt.tight_layout()\n",
       "    plt.savefig(os.path.join(config['visualize_dir'], 'lstm-unet_temporal_analysis.png'))\n",
       "    plt.show()\n",
       "\n",
       "# Analyze temporal predictions\n",
       "# Uncomment after loading a trained model\n",
       "# analyze_temporal_predictions(best_model, X_data, y_data, config)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 11. Create Temporal Animation\n",
       "\n",
       "Visualize how the model predictions change over time."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def create_temporal_animation(model, X_data, y_data, config, sample_idx=0):\n",
       "    \"\"\"Create an animation showing how predictions change over time\"\"\"\n",
       "    from src.utils import create_time_series_animation\n",
       "    \n",
       "    model.eval()\n",
       "    model.to(device)\n",
       "    \n",
       "    # Create predictions for different time slices\n",
       "    predictions = []\n",
       "    \n",
       "    for t in range(5, config['time_steps'] + 1):\n",
       "        # Create dataset with t time steps\n",
       "        temp_dataset = TemporalUrbanCropDataset(X_data[sample_idx:sample_idx+1], \n",
       "                                              y_data[sample_idx:sample_idx+1], \n",
       "                                              time_steps=t)\n",
       "        x_temp, y_temp = temp_dataset[0]\n",
       "        \n",
       "        # Make prediction\n",
       "        with torch.no_grad():\n",
       "            x_temp = x_temp.unsqueeze(0).to(device)  # Add batch dimension\n",
       "            pred = model(x_temp)\n",
       "        \n",
       "        # Add to predictions\n",
       "        predictions.append(np.transpose(pred[0].cpu().numpy(), (1, 2, 0)))\n",
       "    \n",
       "    # Create animation\n",
       "    animation_path = os.path.join(config['visualize_dir'], 'lstm-unet_temporal_animation.gif')\n",
       "    ani = create_time_series_animation(\n",
       "        data=np.array(predictions),\n",
       "        title=\"LSTM-UNet Predictions Over Time\",\n",
       "        save_path=animation_path,\n",
       "        fps=2\n",
       "    )\n",
       "    \n",
       "    return animation_path\n",
       "\n",
       "# Create temporal animation\n",
       "# Uncomment after loading a trained model\n",
       "# animation_path = create_temporal_animation(best_model, X_data, y_data, config)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 12. Conclusion\n",
       "\n",
       "This notebook demonstrated how to load, train, evaluate, and use the LSTM-UNet model for spatio-temporal urban crop yield prediction. The LSTM-UNet model combines LSTM for temporal processing with U-Net for spatial processing, making it suitable for datasets with both spatial and temporal components.\n",
       "\n",
       "For a full training, you would increase the number of epochs and potentially tune hyperparameters for better performance."
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }