{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Conditional GAN (CGAN) Model Testing Notebook\n",
       "\n",
       "This notebook tests the Conditional GAN (CGAN) model for urban crop yield prediction. CGANs are generative models that can create synthetic data conditioned on specific inputs, making them suitable for generating crop yield predictions under different conditions."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 1. Setup and Imports"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import os\n",
       "import numpy as np\n",
       "import torch\n",
       "from torch.utils.data import DataLoader, random_split\n",
       "import matplotlib.pyplot as plt\n",
       "import sys\n",
       "\n",
       "# Add src to path for imports\n",
       "sys.path.append('.')\n",
       "\n",
       "# Import custom modules\n",
       "from src.models.cgan import Generator, Discriminator\n",
       "from src.data.dataset import UrbanCropDataset\n",
       "from src.training import CGANTrainer\n",
       "from src.utils import set_seed, get_device, ensure_dir\n",
       "\n",
       "# Set random seed for reproducibility\n",
       "set_seed(42)\n",
       "\n",
       "# Check for CUDA\n",
       "device = get_device()\n",
       "print(f\"Using device: {device}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. Configuration"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Configuration settings\n",
       "config = {\n",
       "    'data_dir': 'data/processed',  # Directory with processed data\n",
       "    'model_dir': 'models',         # Directory to save trained models\n",
       "    'visualize_dir': 'visualizations',  # Directory for visualizations\n",
       "    'batch_size': 32,              # Batch size for training\n",
       "    'epochs': 10,                  # Number of epochs (reduced for testing)\n",
       "    'learning_rate': 0.0002,       # Learning rate for GANs typically lower\n",
       "    'test_split': 0.2,             # Fraction of data for testing\n",
       "    'val_split': 0.1,              # Fraction of training data for validation\n",
       "    'z_size': 100,                 # Size of the latent space vector\n",
       "    'class_num': 10,               # Number of condition classes\n",
       "    'img_size': 32,                # Size of the generated images\n",
       "    'generator_layer_size': [256, 512, 1024],  # Sizes of generator layers\n",
       "    'discriminator_layer_size': [1024, 512, 256]  # Sizes of discriminator layers\n",
       "}\n",
       "\n",
       "# Create necessary directories\n",
       "ensure_dir(config['model_dir'])\n",
       "cgan_samples_dir = os.path.join(config['visualize_dir'], 'cgan_samples')\n",
       "ensure_dir(cgan_samples_dir)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 3. Load Data\n",
       "\n",
       "For this notebook, we assume that the data has already been processed and saved as numpy arrays. If not, you'll need to run the data processing scripts first."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Load processed data\n",
       "def load_data(config):\n",
       "    \"\"\"Load preprocessed data\"\"\"\n",
       "    x_path = os.path.join(config['data_dir'], 'years_array_32_segmented_prevUrb.npy')\n",
       "    y_path = os.path.join(config['data_dir'], 'crops_array_32_segmented_prevUrb.npy')\n",
       "    \n",
       "    if os.path.exists(x_path) and os.path.exists(y_path):\n",
       "        print(\"Loading preprocessed data...\")\n",
       "        X_data = np.load(x_path)\n",
       "        y_data = np.load(y_path)\n",
       "        print(f\"X_data shape: {X_data.shape}\")\n",
       "        print(f\"y_data shape: {y_data.shape}\")\n",
       "        return X_data, y_data\n",
       "    else:\n",
       "        raise FileNotFoundError(f\"Preprocessed data not found at {x_path} and {y_path}. Please run data preprocessing first.\")\n",
       "\n",
       "try:\n",
       "    X_data, y_data = load_data(config)\n",
       "    \n",
       "    # Sample visualization of the data\n",
       "    plt.figure(figsize=(15, 5))\n",
       "    \n",
       "    # Input features (first sample, first 3 channels)\n",
       "    plt.subplot(1, 2, 1)\n",
       "    plt.imshow(np.transpose(X_data[0][:3], (1, 2, 0)))\n",
       "    plt.title('Input Features (First 3 Channels)')\n",
       "    plt.axis('off')\n",
       "    \n",
       "    # Target output\n",
       "    plt.subplot(1, 2, 2)\n",
       "    plt.imshow(np.transpose(y_data[0], (1, 2, 0)))\n",
       "    plt.title('Target Output')\n",
       "    plt.axis('off')\n",
       "    \n",
       "    plt.tight_layout()\n",
       "    plt.show()\n",
       "    \n",
       "except FileNotFoundError as e:\n",
       "    print(f\"Error: {e}\")\n",
       "    print(\"Using dummy data for demonstration purposes...\")\n",
       "    # Create dummy data for demonstration\n",
       "    X_data = np.random.rand(100, 15, 32, 32)  # [samples, channels, height, width]\n",
       "    y_data = np.random.rand(100, 3, 32, 32)   # [samples, channels, height, width]\n",
       "    print(f\"Dummy X_data shape: {X_data.shape}\")\n",
       "    print(f\"Dummy y_data shape: {y_data.shape}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 4. Preprocess Data for CGAN\n",
       "\n",
       "For CGAN, we need to prepare the data differently. We'll use the first channel of the output as the target image, and create condition labels from the input data features."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def preprocess_for_cgan(X_data, y_data, config):\n",
       "    \"\"\"Preprocess data for CGAN training\"\"\"\n",
       "    # For simplicity, we'll use the first channel of y_data as the target image\n",
       "    target_images = y_data[:, 0, :, :].reshape(-1, 1, config['img_size'], config['img_size'])\n",
       "    \n",
       "    # Create condition labels from the input features\n",
       "    # We'll use a simple approach - cluster the mean of input features into class_num clusters\n",
       "    feature_means = np.mean(X_data, axis=(1, 2, 3))\n",
       "    \n",
       "    # Create class labels by binning the feature means\n",
       "    bins = np.linspace(feature_means.min(), feature_means.max(), config['class_num'] + 1)\n",
       "    condition_labels = np.digitize(feature_means, bins) - 1\n",
       "    condition_labels = np.clip(condition_labels, 0, config['class_num'] - 1)\n",
       "    \n",
       "    print(f\"Target images shape: {target_images.shape}\")\n",
       "    print(f\"Condition labels shape: {condition_labels.shape}\")\n",
       "    print(f\"Condition label distribution: {np.bincount(condition_labels)}\")\n",
       "    \n",
       "    return target_images, condition_labels\n",
       "\n",
       "# Preprocess data for CGAN\n",
       "target_images, condition_labels = preprocess_for_cgan(X_data, y_data, config)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 5. Create Data Loaders"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def create_data_loaders(target_images, condition_labels, config):\n",
       "    \"\"\"Create train, validation, and test data loaders\"\"\"\n",
       "    # Convert to tensor dataset\n",
       "    images_tensor = torch.tensor(target_images, dtype=torch.float32)\n",
       "    labels_tensor = torch.tensor(condition_labels, dtype=torch.long)\n",
       "    \n",
       "    # Create custom dataset\n",
       "    class CGANDataset(torch.utils.data.Dataset):\n",
       "        def __init__(self, images, labels):\n",
       "            self.images = images\n",
       "            self.labels = labels\n",
       "        \n",
       "        def __len__(self):\n",
       "            return len(self.images)\n",
       "        \n",
       "        def __getitem__(self, idx):\n",
       "            return self.images[idx], self.labels[idx]\n",
       "    \n",
       "    dataset = CGANDataset(images_tensor, labels_tensor)\n",
       "    \n",
       "    # Determine the number of samples for each split\n",
       "    total_samples = len(dataset)\n",
       "    test_size = int(total_samples * config['test_split'])\n",
       "    train_size = total_samples - test_size\n",
       "    val_size = int(train_size * config['val_split'])\n",
       "    train_size = train_size - val_size\n",
       "    \n",
       "    print(f\"Total samples: {total_samples}\")\n",
       "    print(f\"Training samples: {train_size}\")\n",
       "    print(f\"Validation samples: {val_size}\")\n",
       "    print(f\"Test samples: {test_size}\")\n",
       "    \n",
       "    # Split into train, validation, and test sets\n",
       "    train_dataset, test_dataset = random_split(\n",
       "        dataset, [train_size + val_size, test_size],\n",
       "        generator=torch.Generator().manual_seed(42)\n",
       "    )\n",
       "    \n",
       "    train_dataset, val_dataset = random_split(\n",
       "        train_dataset, [train_size, val_size],\n",
       "        generator=torch.Generator().manual_seed(42)\n",
       "    )\n",
       "    \n",
       "    # Create data loaders\n",
       "    train_loader = DataLoader(\n",
       "        train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=2\n",
       "    )\n",
       "    \n",
       "    val_loader = DataLoader(\n",
       "        val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=2\n",
       "    )\n",
       "    \n",
       "    test_loader = DataLoader(\n",
       "        test_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=2\n",
       "    )\n",
       "    \n",
       "    return train_loader, val_loader, test_loader\n",
       "\n",
       "# Create data loaders\n",
       "train_loader, val_loader, test_loader = create_data_loaders(target_images, condition_labels, config)\n",
       "\n",
       "# Verify the data\n",
       "for images, labels in train_loader:\n",
       "    print(f\"Batch shapes:\")\n",
       "    print(f\"Images shape: {images.shape}\")\n",
       "    print(f\"Labels shape: {labels.shape}\")\n",
       "    \n",
       "    # Display a few samples\n",
       "    plt.figure(figsize=(15, 4))\n",
       "    for i in range(5):\n",
       "        plt.subplot(1, 5, i+1)\n",
       "        plt.imshow(images[i, 0].numpy(), cmap='gray')\n",
       "        plt.title(f\"Class {labels[i].item()}\")\n",
       "        plt.axis('off')\n",
       "    plt.tight_layout()\n",
       "    plt.show()\n",
       "    break"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 6. Initialize CGAN Model"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def initialize_cgan(config):\n",
       "    \"\"\"Initialize CGAN models and trainer\"\"\"\n",
       "    # Create generator\n",
       "    generator = Generator(\n",
       "        z_size=config['z_size'],\n",
       "        class_num=config['class_num'],\n",
       "        generator_layer_size=config['generator_layer_size'],\n",
       "        img_size=config['img_size']\n",
       "    )\n",
       "    \n",
       "    # Create discriminator\n",
       "    discriminator = Discriminator(\n",
       "        img_size=config['img_size'],\n",
       "        class_num=config['class_num'],\n",
       "        discriminator_layer_size=config['discriminator_layer_size']\n",
       "    )\n",
       "    \n",
       "    print(f\"Generator created with {sum(p.numel() for p in generator.parameters() if p.requires_grad)} trainable parameters\")\n",
       "    print(f\"Discriminator created with {sum(p.numel() for p in discriminator.parameters() if p.requires_grad)} trainable parameters\")\n",
       "    \n",
       "    # Create trainer\n",
       "    trainer = CGANTrainer(\n",
       "        generator, \n",
       "        discriminator, \n",
       "        z_size=config['z_size'], \n",
       "        class_num=config['class_num'], \n",
       "        device=device\n",
       "    )\n",
       "    \n",
       "    trainer.compile(optimizer='adam', learning_rate=config['learning_rate'])\n",
       "    \n",
       "    return generator, discriminator, trainer\n",
       "\n",
       "# Initialize CGAN model\n",
       "generator, discriminator, trainer = initialize_cgan(config)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 7. Train the CGAN Model\n",
       "\n",
       "Train the CGAN model. Note that GANs are known to be difficult to train and may require careful tuning."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def train_cgan(trainer, train_loader, config):\n",
       "    \"\"\"Train the CGAN model\"\"\"\n",
       "    # Create output directory for samples\n",
       "    samples_dir = os.path.join(config['visualize_dir'], 'cgan_samples')\n",
       "    ensure_dir(samples_dir)\n",
       "    \n",
       "    # Train the model\n",
       "    print(f\"Starting training for {config['epochs']} epochs...\")\n",
       "    \n",
       "    try:\n",
       "        history = trainer.fit(\n",
       "            train_loader,\n",
       "            epochs=config['epochs'],\n",
       "            sample_interval=1,  # Generate samples every epoch\n",
       "            save_dir=samples_dir\n",
       "        )\n",
       "    except KeyboardInterrupt:\n",
       "        print(\"Training interrupted by user\")\n",
       "    \n",
       "    # Save the models\n",
       "    model_dir = os.path.join(config['model_dir'], 'cgan')\n",
       "    trainer.save_model(model_dir)\n",
       "    \n",
       "    return trainer\n",
       "\n",
       "# Train the CGAN model (uncomment to run training)\n",
       "# trainer = train_cgan(trainer, train_loader, config)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 8. Plot Training History\n",
       "\n",
       "After training, plot the generator and discriminator losses over epochs."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def plot_history(trainer, config):\n",
       "    \"\"\"Plot training history\"\"\"\n",
       "    history_path = os.path.join(config['visualize_dir'], 'cgan_history.png')\n",
       "    trainer.plot_history(save_path=history_path)\n",
       "    \n",
       "# If you've trained the model, uncomment to plot the history\n",
       "# plot_history(trainer, config)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 9. Load Trained Model"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def load_trained_cgan(config):\n",
       "    \"\"\"Load a trained CGAN model\"\"\"\n",
       "    # Initialize models\n",
       "    generator = Generator(\n",
       "        z_size=config['z_size'],\n",
       "        class_num=config['class_num'],\n",
       "        generator_layer_size=config['generator_layer_size'],\n",
       "        img_size=config['img_size']\n",
       "    )\n",
       "    \n",
       "    discriminator = Discriminator(\n",
       "        img_size=config['img_size'],\n",
       "        class_num=config['class_num'],\n",
       "        discriminator_layer_size=config['discriminator_layer_size']\n",
       "    )\n",
       "    \n",
       "    # Create trainer\n",
       "    trainer = CGANTrainer(\n",
       "        generator, \n",
       "        discriminator, \n",
       "        z_size=config['z_size'], \n",
       "        class_num=config['class_num'], \n",
       "        device=device\n",
       "    )\n",
       "    \n",
       "    trainer.compile(optimizer='adam', learning_rate=config['learning_rate'])\n",
       "    \n",
       "    # Load model\n",
       "    model_dir = os.path.join(config['model_dir'], 'cgan')\n",
       "    if os.path.exists(model_dir):\n",
       "        print(f\"Loading CGAN model from {model_dir}\")\n",
       "        trainer.load_model(model_dir)\n",
       "    else:\n",
       "        print(f\"Trained model not found at {model_dir}. Using untrained model.\")\n",
       "    \n",
       "    return generator, discriminator, trainer\n",
       "\n",
       "# Load trained model\n",
       "# Uncomment if you have a trained model\n",
       "# generator, discriminator, trainer = load_trained_cgan(config)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 10. Generate Samples with CGAN\n",
       "\n",
       "Generate samples from the trained CGAN for each class condition."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def generate_samples(generator, config):\n",
       "    \"\"\"Generate samples from the CGAN for each class\"\"\"\n",
       "    generator.eval()\n",
       "    generator.to(device)\n",
       "    \n",
       "    # Generate 5 samples for each class\n",
       "    n_samples_per_class = 5\n",
       "    n_classes = config['class_num']\n",
       "    \n",
       "    with torch.no_grad():\n",
       "        # Create a grid of samples\n",
       "        fig, axs = plt.subplots(n_classes, n_samples_per_class, figsize=(15, 3*n_classes))\n",
       "        \n",
       "        for class_idx in range(n_classes):\n",
       "            # Generate random noise\n",
       "            z = torch.randn(n_samples_per_class, config['z_size']).to(device)\n",
       "            \n",
       "            # Create labels for this class\n",
       "            labels = torch.full((n_samples_per_class,), class_idx, dtype=torch.long).to(device)\n",
       "            \n",
       "            # Generate images\n",
       "            fake_images = generator(z, labels)\n",
       "            fake_images = fake_images.cpu().detach()\n",
       "            \n",
       "            # Plot\n",
       "            for i in range(n_samples_per_class):\n",
       "                ax = axs[class_idx, i]\n",
       "                img = fake_images[i, 0].numpy()\n",
       "                ax.imshow(img, cmap='gray')\n",
       "                if i == 0:\n",
       "                    ax.set_ylabel(f'Class {class_idx}')\n",
       "                ax.axis('off')\n",
       "        \n",
       "        plt.tight_layout()\n",
       "        plt.savefig(os.path.join(config['visualize_dir'], 'cgan_generated_samples.png'))\n",
       "        plt.show()\n",
       "\n",
       "# Generate samples\n",
       "# Uncomment after loading a trained model\n",
       "# generate_samples(generator, config)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 11. Compare CGAN Samples with Real Data\n",
       "\n",
       "Compare the generated samples with real data for each class."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def compare_real_vs_generated(generator, target_images, condition_labels, config):\n",
       "    \"\"\"Compare real data with generated samples for each class\"\"\"\n",
       "    generator.eval()\n",
       "    generator.to(device)\n",
       "    \n",
       "    n_classes = config['class_num']\n",
       "    \n",
       "    # Convert to numpy for easier handling\n",
       "    target_images_np = target_images\n",
       "    condition_labels_np = condition_labels\n",
       "    \n",
       "    with torch.no_grad():\n",
       "        plt.figure(figsize=(15, 3*n_classes))\n",
       "        \n",
       "        for class_idx in range(n_classes):\n",
       "            # Get real images for this class\n",
       "            class_indices = np.where(condition_labels_np == class_idx)[0]\n",
       "            \n",
       "            if len(class_indices) == 0:\n",
       "                print(f\"No real samples for class {class_idx}\")\n",
       "                continue\n",
       "                \n",
       "            # Take up to 3 real samples\n",
       "            n_real_samples = min(3, len(class_indices))\n",
       "            real_indices = class_indices[:n_real_samples]\n",
       "            real_samples = target_images_np[real_indices]\n",
       "            \n",
       "            # Generate 3 fake samples\n",
       "            z = torch.randn(3, config['z_size']).to(device)\n",
       "            labels = torch.full((3,), class_idx, dtype=torch.long).to(device)\n",
       "            fake_samples = generator(z, labels).cpu().detach().numpy()\n",
       "            \n",
       "            # Plot real samples\n",
       "            for i in range(n_real_samples):\n",
       "                plt.subplot(n_classes, 6, class_idx*6 + i + 1)\n",
       "                plt.imshow(real_samples[i, 0], cmap='gray')\n",
       "                plt.title(f\"Real {i+1}\" if i > 0 else f\"Real Class {class_idx}\")\n",
       "                plt.axis('off')\n",
       "            \n",
       "            # Fill empty spaces if fewer than 3 real samples\n",
       "            for i in range(n_real_samples, 3):\n",
       "                plt.subplot(n_classes, 6, class_idx*6 + i + 1)\n",
       "                plt.axis('off')\n",
       "            \n",
       "            # Plot generated samples\n",
       "            for i in range(3):\n",
       "                plt.subplot(n_classes, 6, class_idx*6 + i + 4)\n",
       "                plt.imshow(fake_samples[i, 0], cmap='gray')\n",
       "                plt.title(f\"Generated {i+1}\" if i > 0 else f\"Generated Class {class_idx}\")\n",
       "                plt.axis('off')\n",
       "        \n",
       "        plt.tight_layout()\n",
       "        plt.savefig(os.path.join(config['visualize_dir'], 'cgan_real_vs_generated.png'))\n",
       "        plt.show()\n",
       "\n",
       "# Compare real vs generated samples\n",
       "# Uncomment after loading a trained model\n",
       "# compare_real_vs_generated(generator, target_images, condition_labels, config)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 12. Generate Interpolated Samples\n",
       "\n",
       "Generate samples by interpolating in the latent space to see smooth transitions."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def generate_interpolations(generator, config):\n",
       "    \"\"\"Generate samples by interpolating in the latent space\"\"\"\n",
       "    generator.eval()\n",
       "    generator.to(device)\n",
       "    \n",
       "    with torch.no_grad():\n",
       "        # Interpolate between two random points in the latent space\n",
       "        z_start = torch.randn(1, config['z_size']).to(device)\n",
       "        z_end = torch.randn(1, config['z_size']).to(device)\n",
       "        \n",
       "        # Create 10 interpolation steps\n",
       "        n_steps = 10\n",
       "        interpolations = []\n",
       "        \n",
       "        # Choose a class\n",
       "        class_idx = np.random.randint(0, config['class_num'])\n",
       "        label = torch.full((1,), class_idx, dtype=torch.long).to(device)\n",
       "        \n",
       "        plt.figure(figsize=(15, 3))\n",
       "        plt.suptitle(f\"Latent Space Interpolation for Class {class_idx}\")\n",
       "        \n",
       "        for i in range(n_steps):\n",
       "            # Linear interpolation\n",
       "            alpha = i / (n_steps - 1)\n",
       "            z_interp = z_start * (1 - alpha) + z_end * alpha\n",
       "            \n",
       "            # Generate image\n",
       "            fake_image = generator(z_interp, label)\n",
       "            fake_image = fake_image.cpu().detach().numpy()\n",
       "            \n",
       "            # Plot\n",
       "            plt.subplot(1, n_steps, i+1)\n",
       "            plt.imshow(fake_image[0, 0], cmap='gray')\n",
       "            plt.title(f\"Step {i+1}\")\n",
       "            plt.axis('off')\n",
       "        \n",
       "        plt.tight_layout()\n",
       "        plt.savefig(os.path.join(config['visualize_dir'], 'cgan_interpolation.png'))\n",
       "        plt.show()\n",
       "        \n",
       "        # Interpolate between classes with fixed latent vector\n",
       "        z_fixed = torch.randn(1, config['z_size']).to(device)\n",
       "        \n",
       "        plt.figure(figsize=(15, 3))\n",
       "        plt.suptitle(\"Class Conditioning Interpolation with Fixed Latent Vector\")\n",
       "        \n",
       "        for i in range(n_steps):\n",
       "            # Linear interpolation between classes (in embedding space)\n",
       "            class_idx = i % config['class_num']\n",
       "            label = torch.full((1,), class_idx, dtype=torch.long).to(device)\n",
       "            \n",
       "            # Generate image\n",
       "            fake_image = generator(z_fixed, label)\n",
       "            fake_image = fake_image.cpu().detach().numpy()\n",
       "            \n",
       "            # Plot\n",
       "            plt.subplot(1, n_steps, i+1)\n",
       "            plt.imshow(fake_image[0, 0], cmap='gray')\n",
       "            plt.title(f\"Class {class_idx}\")\n",
       "            plt.axis('off')\n",
       "        \n",
       "        plt.tight_layout()\n",
       "        plt.savefig(os.path.join(config['visualize_dir'], 'cgan_class_interpolation.png'))\n",
       "        plt.show()\n",
       "\n",
       "# Generate interpolated samples\n",
       "# Uncomment after loading a trained model\n",
       "# generate_interpolations(generator, config)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 13. Evaluate the Discriminator on Real and Generated Samples\n",
       "\n",
       "Test how well the discriminator can tell apart real and generated samples."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def evaluate_discriminator(generator, discriminator, test_loader, config):\n",
       "    \"\"\"Evaluate the discriminator on real and generated samples\"\"\"\n",
       "    generator.eval()\n",
       "    discriminator.eval()\n",
       "    generator.to(device)\n",
       "    discriminator.to(device)\n",
       "    \n",
       "    real_scores = []\n",
       "    fake_scores = []\n",
       "    \n",
       "    with torch.no_grad():\n",
       "        for images, labels in test_loader:\n",
       "            # Evaluate on real samples\n",
       "            images = images.to(device)\n",
       "            labels = labels.to(device)\n",
       "            real_validity = discriminator(images, labels)\n",
       "            real_scores.extend(real_validity.cpu().numpy())\n",
       "            \n",
       "            # Generate fake samples with the same labels\n",
       "            z = torch.randn(labels.size(0), config['z_size']).to(device)\n",
       "            fake_images = generator(z, labels)\n",
       "            fake_validity = discriminator(fake_images, labels)\n",
       "            fake_scores.extend(fake_validity.cpu().numpy())\n",
       "            \n",
       "            # Limit the evaluation to a few batches\n",
       "            if len(real_scores) > 200:\n",
       "                break\n",
       "    \n",
       "    # Convert to numpy arrays\n",
       "    real_scores = np.array(real_scores)\n",
       "    fake_scores = np.array(fake_scores)\n",
       "    \n",
       "    # Plot histograms of the scores\n",
       "    plt.figure(figsize=(12, 6))\n",
       "    plt.hist(real_scores, bins=20, alpha=0.5, label='Real Samples')\n",
       "    plt.hist(fake_scores, bins=20, alpha=0.5, label='Generated Samples')\n",
       "    plt.xlabel('Discriminator Score')\n",
       "    plt.ylabel('Count')\n",
       "    plt.title('Discriminator Evaluation')\n",
       "    plt.legend()\n",
       "    plt.savefig(os.path.join(config['visualize_dir'], 'cgan_discriminator_evaluation.png'))\n",
       "    plt.show()\n",
       "    \n",
       "    # Calculate statistics\n",
       "    print(f\"Real samples - Mean score: {real_scores.mean():.4f}, Std: {real_scores.std():.4f}\")\n",
       "    print(f\"Fake samples - Mean score: {fake_scores.mean():.4f}, Std: {fake_scores.std():.4f}\")\n",
       "    \n",
       "    # Calculate accuracy\n",
       "    real_correct = (real_scores > 0.5).sum()\n",
       "    fake_correct = (fake_scores < 0.5).sum()\n",
       "    total = len(real_scores) + len(fake_scores)\n",
       "    accuracy = (real_correct + fake_correct) / total\n",
       "    \n",
       "    print(f\"Discriminator accuracy: {accuracy:.4f}\")\n",
       "    print(f\"Real samples correctly identified: {real_correct / len(real_scores):.4f}\")\n",
       "    print(f\"Fake samples correctly identified: {fake_correct / len(fake_scores):.4f}\")\n",
       "\n",
       "# Evaluate discriminator\n",
       "# Uncomment after loading a trained model\n",
       "# evaluate_discriminator(generator, discriminator, test_loader, config)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 14. Conclusion\n",
       "\n",
       "This notebook demonstrated how to train and evaluate a Conditional GAN (CGAN) for urban crop yield prediction. CGANs can generate synthetic data conditioned on specific inputs, which can be useful for data augmentation, exploring different scenarios, or generating predictions under various conditions.\n",
       "\n",
       "Training GANs is known to be challenging and may require careful tuning of hyperparameters, so expect some experimentation to get good results. For better performance, you might want to try:\n",
       "\n",
       "1. Using more sophisticated architectures\n",
       "2. Implementing spectral normalization or other stabilization techniques\n",
       "3. Experimenting with different loss functions (e.g., Wasserstein GAN)\n",
       "4. Training for more epochs with learning rate scheduling"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }